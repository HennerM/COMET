COMET: High-quality Machine Translation Evaluation
===================================================

.. image:: _static/img/COMET_lockup-dark.png
   :width: 800
   :alt: COMET by Unbabel

What is COMET
==============

COMET is an open-source framework for MT evaluation that can be used for two purposes:

* To evaluate MT systems with our currently available high-performing metrics (check: :ref:`models:COMET Metrics`).
* To train and develop new metrics.




Contents:
=========

.. toctree::
   :maxdepth: 2

   installation
   running
   models
   training


License
==============

Free software: Apache License 2.0

Contributing
==============
We welcome contributions to improve COMET. Please refer to `CONTRIBUTING.md <https://github.com/Unbabel/COMET/blob/master/CONTRIBUTING.md>`_ for quick instructions or to contributing instructions for more detailed instructions on how to set up your development environment.

Publications
=========

* `COMET: A Neural Framework for MT Evaluation <https://www.aclweb.org/anthology/2020.emnlp-main.213>`_ 
* `Unbabel's Participation in the WMT20 Metrics Shared Task <https://aclanthology.org/2020.wmt-1.101/>`_ 
* `COMET - Deploying a New State-of-the-art MT Evaluation Metric in Production <https://www.aclweb.org/anthology/2020.amta-user.4/>`_  
* `Uncertainty-Aware Machine Translation Evaluation <https://aclanthology.org/2021.findings-emnlp.330/>`_ 
* `Are References Really Needed? Unbabel-IST 2021 Submission for the Metrics Shared Task <http://statmt.org/wmt21/pdf/2021.wmt-1.111.pdf>`_ 

Library Reference
==================

.. toctree::
   :maxdepth: 2

   library
